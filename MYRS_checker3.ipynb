{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "update! (generic function with 4 methods)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#include(\"MAB_module.jl\")\n",
    "include(\"environment.jl\")\n",
    "include(\"algorithm_base.jl\")\n",
    "include(\"eps_greedy.jl\")\n",
    "include(\"rs.jl\")\n",
    "include(\"lsx.jl\")\n",
    "#include(\"meta-bandit.jl\")\n",
    "include(\"ucb1tuned.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using Plots\n",
    "using Statistics\n",
    "#using Base.Threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mutable struct MYRS <: Algorithm\n",
    "    env::Environment\n",
    "    actionValues::Vector{Float64}\n",
    "    counts::Vector{Float64}             #numbers of selection of each arm.\n",
    "    sum_rewards::Vector             #sum of an earned reward of each arm\n",
    "    average::Vector\n",
    "    r::Float64\n",
    "    gamma::Float64\n",
    "    alpha_r::Float64\n",
    "    n::Float64\n",
    "    opt::Bool\n",
    "    test_name::String\n",
    "    #constructor\n",
    "    function MYRS(;env::Environment, r::Float64, gamma::Float64, alpha_r::Float64, n=0.,opt=false, test_name=\"\")\n",
    "        return new( env,\n",
    "                    zeros(env.arm_num),\n",
    "                    zeros(env.arm_num),\n",
    "                    zeros(env.arm_num),\n",
    "                    zeros(env.arm_num),\n",
    "                    r,\n",
    "                    gamma,\n",
    "                    alpha_r,\n",
    "                    n,\n",
    "                    opt,\n",
    "                    test_name)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "update! (generic function with 5 methods)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function init!(algo::MYRS)\n",
    "    init_algo!(algo)\n",
    "    if algo.opt\n",
    "        sorted_pro = sort(algo.env.arm_pros, rev=true)\n",
    "        algo.r = (sorted_pro[1] + sorted_pro[2]) / 2\n",
    "    else\n",
    "        algo.r = 1.\n",
    "    end\n",
    "end\n",
    "\n",
    "function select_arm(algo::MYRS)\n",
    "    #return index of maximum value in the action values.\n",
    "    return greedy(algo)\n",
    "end\n",
    "\n",
    "function calc_value(algo::MYRS, selected, reward)\n",
    "        \n",
    "    if algo.test_name == \"gamma\"\n",
    "        algo.average[selected] = algo.sum_rewards[selected] / algo.counts[selected]\n",
    "        #for i=1:algo.env.arm_num\n",
    "        #    algo.counts[i] = algo.gamma * algo.counts[i]\n",
    "        #    algo.sum_rewards[i] = algo.gamma * algo.sum_rewards[i]\n",
    "        #end\n",
    "        \n",
    "    else\n",
    "        algo.average[selected] = algo.sum_rewards[selected] / algo.counts[selected]\n",
    "        #algo.r += algo.alpha_r * (algo.average[selected] - algo.r)\n",
    "        #algo.r += algo.alpha_r * (algo.sum_rewards[selected] / algo.counts[selected] - algo.r)\n",
    "    end\n",
    "    \n",
    "    if !algo.opt\n",
    "        algo.r += algo.alpha_r * (reward - algo.r)\n",
    "    end\n",
    "    \n",
    "    if algo.test_name == \"gamma\"\n",
    "#         for i=1:algo.env.arm_num\n",
    "#             algo.actionValues[i] = algo.gamma * algo.actionValues[i]\n",
    "#         end\n",
    "        algo.actionValues[selected] += reward - algo.r\n",
    "    else\n",
    "        algo.actionValues[selected] = algo.counts[selected]*(algo.average[selected] - algo.r)\n",
    "    end\n",
    "\n",
    "    #@show algo.r selected\n",
    "end\n",
    "\n",
    "#update each variables and calc parameters for epsilon greedy algorithm\n",
    "function update!(algo::MYRS)\n",
    "    selected = select_arm(algo)\n",
    "    reward = get_reward(algo.env.arm_pros, selected)\n",
    "\n",
    "    #update this experiment's current state.\n",
    "    #algo.n[selected] = (reward + algo.gamma*algo.n[selected])/(1. + algo.gamma)\n",
    "    algo.counts[selected] = algo.counts[selected] + 1\n",
    "    algo.sum_rewards[selected] += reward\n",
    "\n",
    "    #calculation of action value and save.\n",
    "    calc_value(algo, selected, reward)\n",
    "    \n",
    "#     for i=1:algo.env.arm_num\n",
    "#         algo.counts[i] = algo.gamma * algo.counts[i]\n",
    "#     end\n",
    "\n",
    "    #calc regret.\n",
    "    regret = algo.env.max_pro - algo.env.arm_pros[selected]\n",
    "\n",
    "    return selected, regret, reward\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "simulation (generic function with 1 method)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function simulation(;sim_num::Int, steps::Int, update_per::Int, arm_num=4, dynamic=false)\n",
    "    #argument checking.\n",
    "    if dynamic && update_per <= steps && steps % update_per != 0\n",
    "        println(\"update number error.\")\n",
    "        return\n",
    "    end\n",
    "\n",
    "    update_num = div(steps, update_per)#convert(Int64, steps/update_per)\n",
    "    env = Environment(arm_num)\n",
    "\n",
    "    algo_dict = Dict()\n",
    "    \n",
    "    for alpha=[0.0005]\n",
    "        gamma = 1.\n",
    "        #alpha = 1/(10^i)\n",
    "        algo_dict[\"RS \\\\alpha=$alpha\"] = MYRS(env=env, r=1., gamma=gamma, alpha_r=alpha, test_name=\"gamma\")\n",
    "    end\n",
    "    algo_dict[\"RS opt \\\\gamma\"] = MYRS(env=env, r=1., gamma=0.999, alpha_r=0.0005, opt=true, test_name=\"gamma\")\n",
    "    #algo_dict[\"RS opt\"] = MYRS(env=env, r=1., gamma=0.999, alpha_r=0.0005, opt=true)\n",
    "#     for gamma in [0.7, 0.5, 0.3]\n",
    "#         algo_dict[\"MYRS merge gamma=$gamma\"] = MYRS(env, 1., gamma, 0.001, \"merge\")\n",
    "#     end\n",
    "\n",
    "    algo_dict[\"RS\"] = RS(env)\n",
    "    #algo_dict[\"UCB1 tuned\"] = UCB1(env, true)\n",
    "    \n",
    "    regret_means, win_means, action_vals = Vector{}(), Vector{}(), Vector{}()\n",
    "    for algorithm in values(algo_dict)\n",
    "        regrets, wins = zeros(sim_num, steps), zeros(sim_num, steps)\n",
    "        #action_val = Vector{}()\n",
    "        for sim in 1:sim_num\n",
    "            ds = rand(update_num,arm_num)\n",
    "            update_env!(env, ds[1, :])\n",
    "            init!(algorithm)\n",
    "            regret = 0.\n",
    "            \n",
    "            for step in 1:steps-1\n",
    "                selected, rgt, reward = update!(algorithm)\n",
    "\n",
    "                #save each parameter.\n",
    "                regret += rgt\n",
    "                regrets[sim, step] = regret\n",
    "\n",
    "                if selected == env.correct_arm\n",
    "                    wins[sim, step] = 1\n",
    "                end\n",
    "                \n",
    "                if dynamic\n",
    "                    if step % update_per == 0\n",
    "                        ds_idx = div(step, update_per)\n",
    "                        update_env!(env, ds[ds_idx+1, :])\n",
    "                        #println(\"<----------updated------------->\")\n",
    "                        if typeof(algorithm) == RS\n",
    "                            update_r!(algorithm)\n",
    "                        elseif typeof(algorithm) == LSX && algorithm.opt\n",
    "                            algorithm.r = opt_r(algorithm.env.arm_pros)\n",
    "                        elseif typeof(algorithm) == MYRS\n",
    "                            if algorithm.opt\n",
    "                                sorted_pro = sort(env.arm_pros, rev=true)\n",
    "                                algorithm.r = (sorted_pro[1] + sorted_pro[2]) / 2\n",
    "                            end\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "\n",
    "            end\n",
    "            if sim % 10 == 0\n",
    "                print(\"$((sim/sim_num)*100) %\")\n",
    "            end\n",
    "        end\n",
    "        push!(regret_means, [mean(regrets[:, i]) for i=1:steps])\n",
    "        push!(win_means, [mean(wins[:, i]) for i=1:steps])\n",
    "        #push!(action_vals, vcat(action_val...))\n",
    "        \n",
    "    end\n",
    "    \n",
    "    println(\"DONE.\")\n",
    "    \n",
    "    #@show action_vals\n",
    "\n",
    "    graph_data = hcat(win_means...)\n",
    "    time = Vector{Int}(1:steps)\n",
    "    #xscale=:log\n",
    "\n",
    "    #graph_data2 = vcat(rslist...)\n",
    "    #@show size(graph_data2)\n",
    "    graph_data2 = hcat(regret_means...)\n",
    "\n",
    "    return graph_data, graph_data2, algo_dict\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 %2.0 %3.0 %4.0 %5.0 %6.0 %7.000000000000001 %8.0 %9.0 %10.0 %11.0 %12.0 %13.0 %14.000000000000002 %15.0 %16.0 %17.0 %18.0 %19.0 %20.0 %21.0 %22.0 %23.0 %24.0 %25.0 %26.0 %27.0 %28.000000000000004 %28.999999999999996 %30.0 %31.0 %32.0 %33.0 %34.0 %35.0 %36.0 %37.0 %38.0 %39.0 %40.0 %41.0 %42.0 %43.0 %44.0 %45.0 %46.0 %47.0 %48.0 %49.0 %50.0 %51.0 %52.0 %53.0 %54.0 %55.00000000000001 %56.00000000000001 %56.99999999999999 %57.99999999999999 %59.0 %60.0 %61.0 %62.0 %63.0 %64.0 %65.0 %66.0 %67.0 %68.0 %69.0 %70.0 %71.0 %72.0 %73.0 %74.0 %75.0 %76.0 %77.0 %78.0 %79.0 %80.0 %81.0 %82.0 %83.0 %84.0 %85.0 %86.0 %87.0 %88.0 %89.0 %90.0 %91.0 %92.0 %93.0 %94.0 %95.0 %96.0 %97.0 %98.0 %99.0 %100.0 %1.0 %2.0 %3.0 %4.0 %5.0 %6.0 %7.000000000000001 %8.0 %9.0 %10.0 %11.0 %12.0 %13.0 %14.000000000000002 %15.0 %16.0 %17.0 %18.0 %19.0 %20.0 %21.0 %22.0 %23.0 %24.0 %25.0 %26.0 %27.0 %28.000000000000004 %28.999999999999996 %30.0 %31.0 %32.0 %33.0 %34.0 %35.0 %36.0 %37.0 %38.0 %39.0 %40.0 %41.0 %42.0 %43.0 %44.0 %45.0 %46.0 %47.0 %48.0 %49.0 %50.0 %51.0 %52.0 %53.0 %54.0 %55.00000000000001 %56.00000000000001 %56.99999999999999 %57.99999999999999 %59.0 %60.0 %61.0 %62.0 %63.0 %64.0 %65.0 %66.0 %67.0 %68.0 %69.0 %70.0 %71.0 %72.0 %73.0 %74.0 %75.0 %76.0 %77.0 %78.0 %79.0 %80.0 %81.0 %82.0 %83.0 %84.0 %85.0 %86.0 %87.0 %88.0 %89.0 %90.0 %91.0 %92.0 %93.0 %94.0 %95.0 %96.0 %97.0 %98.0 %99.0 %100.0 %1.0 %2.0 %3.0 %4.0 %5.0 %6.0 %7.000000000000001 %8.0 %9.0 %10.0 %11.0 %12.0 %13.0 %14.000000000000002 %15.0 %16.0 %17.0 %18.0 %19.0 %20.0 %21.0 %22.0 %23.0 %24.0 %25.0 %26.0 %27.0 %28.000000000000004 %28.999999999999996 %30.0 %31.0 %32.0 %33.0 %34.0 %35.0 %36.0 %37.0 %38.0 %39.0 %40.0 %41.0 %42.0 %43.0 %44.0 %45.0 %46.0 %47.0 %48.0 %49.0 %50.0 %51.0 %52.0 %53.0 %54.0 %55.00000000000001 %56.00000000000001 %56.99999999999999 %57.99999999999999 %59.0 %60.0 %61.0 %62.0 %63.0 %64.0 %65.0 %66.0 %67.0 %68.0 %69.0 %70.0 %71.0 %72.0 %73.0 %74.0 %75.0 %76.0 %77.0 %78.0 %79.0 %80.0 %81.0 %82.0 %83.0 %84.0 %85.0 %86.0 %87.0 %88.0 %89.0 %90.0 %"
     ]
    }
   ],
   "source": [
    "@time g1, g2, algo_dict = simulation(sim_num=1000,\n",
    "                            steps=30000,\n",
    "                            update_per=10000,\n",
    "                            arm_num=20,\n",
    "                            dynamic=false);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "step_axis = [i for i=1:100:size(g1)[1]]\n",
    "graph = [g1[i, :] for i in step_axis]\n",
    "graph = hcat(graph...)'\n",
    "#plot(1:size(g1)[1], g1, label=[\"RS\",\"RS_tuned\"], title=\"Accuracy\")\n",
    "#plot(step_axis, graph, title=\"Accuracy\", label=[key for key in keys(algo_dict)], legend=:bottomright)\n",
    "labels = [key for key in keys(algo_dict)]\n",
    "plot(step_axis, graph, title=\"Accuracy\", label=labels, xlabel=\"step\",ylabel=\"accuracy\", legend=:bottomright)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.0",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
